{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNPds1L7KKY2e6v1JuxUoH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/masao1112/MLFromScratch/blob/main/%5BCompleted%5DDecision_Trees%26Random_Forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWZErFDn3s8X"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "import matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target"
      ],
      "metadata": {
        "id": "XhvmB8fi30I0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[:5], y[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmCqHvny35QM",
        "outputId": "17cd6ed2-c82a-4956-9b1f-fea3119c4175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[5.1, 3.5, 1.4, 0.2],\n",
              "        [4.9, 3. , 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.3, 0.2],\n",
              "        [4.6, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.6, 1.4, 0.2]]),\n",
              " array([0, 0, 0, 0, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 372
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "age = np.array([18, 30, 8, 17, 25, 54, 69, 70, 45])\n",
        "labels = np.array([0, 1, 0, 0, 1, 2, 2, 2, 1]) # 0: Child, 1: Adult, 2: Elderly"
      ],
      "metadata": {
        "id": "ebTrvlDX38mM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_age = sorted(age, reverse=False)\n",
        "sorted_age = np.array(sorted_age)\n",
        "sorted_age"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5o9vs6ih4ym9",
        "outputId": "b3176c07-8b25-40b3-a601-8a497bf619b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8, 17, 18, 25, 30, 45, 54, 69, 70])"
            ]
          },
          "metadata": {},
          "execution_count": 374
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_thresholds(X, n_components=2):\n",
        "  # sort the values in ascending order\n",
        "  sorted_X = sorted(X, reverse=False)\n",
        "  sorted_X = np.array(sorted_X)\n",
        "  result = []\n",
        "  for i in range(len(sorted_X)-n_components):\n",
        "    selected_comps = sorted_X[i:i+n_components]\n",
        "    result.append(sum(selected_comps)/n_components)\n",
        "  return np.array(result)"
      ],
      "metadata": {
        "id": "gZoKuSXB4570"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thresholds = calculate_thresholds(sorted_age)\n",
        "thresholds # thresholds for prediicting teenagers or adults"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hM5QAk-C6EaI",
        "outputId": "b3871854-65ec-4cf3-9b75-6a1bfab6f47f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([12.5, 17.5, 21.5, 27.5, 37.5, 49.5, 61.5])"
            ]
          },
          "metadata": {},
          "execution_count": 376
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split(array, labels, threshold):\n",
        "  left_node = []\n",
        "  right_node = []\n",
        "  left_node_classes = []\n",
        "  right_node_classes = []\n",
        "  preds = np.where(array <= threshold, 0, 1)\n",
        "  for i in range(len(array)):\n",
        "    if preds[i] == 0:\n",
        "      left_node.append(array[i])\n",
        "      left_node_classes.append(labels[i])\n",
        "    else:\n",
        "      right_node.append(array[i])\n",
        "      right_node_classes.append(labels[i])\n",
        "  return np.array(left_node), np.array(right_node), np.array(left_node_classes), np.array(right_node_classes)"
      ],
      "metadata": {
        "id": "2VxCWHYi6VTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_split(X, y, feature, threshold):\n",
        "  left_node = []\n",
        "  right_node = []\n",
        "  left_node_classes = []\n",
        "  right_node_classes = []\n",
        "  m, n = X.shape\n",
        "  preds = np.where(X[:, feature] <= threshold, 0, 1)\n",
        "  for i in range(m):\n",
        "    if preds[i] == 0:\n",
        "      left_node.append(X[i])\n",
        "      left_node_classes.append(y[i])\n",
        "    else:\n",
        "      right_node.append(X[i])\n",
        "      right_node_classes.append(y[i])\n",
        "  return np.array(left_node), np.array(right_node), np.array(left_node_classes), np.array(right_node_classes)"
      ],
      "metadata": {
        "id": "Yn8XaLUfmYvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_entropy(node_labels):\n",
        "  # get the unique labels\n",
        "  unique_labels = np.unique(node_labels)\n",
        "  total_class = len(node_labels) # total number of classes\n",
        "  # calculate the entropy for each class and sum it up\n",
        "  entropy = 0\n",
        "  for i in unique_labels:\n",
        "    n_classi = sum(node_labels == i) # number of elements of classi\n",
        "    pi =  n_classi / total_class\n",
        "    entropy += (-pi * np.log2(pi))\n",
        "  return entropy # 0: homogenious, 1: class labels are equally divided"
      ],
      "metadata": {
        "id": "tq3Fq2WB8pGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the entropy for the root node\n",
        "root_entropy = calculate_entropy(labels)\n",
        "root_entropy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzkUnOv5jdgy",
        "outputId": "b5c2f79a-a750-4967-e280-9aadeee54c24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(1.584962500721156)"
            ]
          },
          "metadata": {},
          "execution_count": 380
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = len(age)\n",
        "for thresh in thresholds:\n",
        "  # Split the root\n",
        "  left_node, right_node, left_node_classes, right_node_classes = split(age, labels, thresh)\n",
        "  # calculate the entropy of child nodes\n",
        "  ln_entropy = calculate_entropy(left_node_classes)\n",
        "  rn_entropy = calculate_entropy(right_node_classes)\n",
        "  ig = root_entropy - (ln_entropy * len(left_node)/n + rn_entropy * len(right_node)/n)\n",
        "  print(left_node_classes, right_node_classes, ln_entropy, rn_entropy, ig)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEe8ZGDF8dSf",
        "outputId": "1e6748b9-10a7-45ab-c119-870cccd901d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] [0 1 0 1 2 2 2 1] 0.0 1.561278124459133 0.1971597234241491\n",
            "[0 0] [0 1 1 2 2 2 1] 0.0 1.4488156357251847 0.4581058951571235\n",
            "[0 0 0] [1 1 2 2 2 1] 0.0 1.0 0.9182958340544894\n",
            "[0 0 0 1] [1 2 2 2 1] 0.8112781244591328 0.9709505944546686 0.6849774484867255\n",
            "[0 1 0 0 1] [2 2 2 1] 0.9709505944546686 0.8112781244591328 0.6849774484867255\n",
            "[0 1 0 0 1 1] [2 2 2] 1.0 0.0 0.9182958340544894\n",
            "[0 1 0 0 1 2 1] [2 2] 1.4488156357251847 0.0 0.4581058951571235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assemble everything and return the optimal threshold\n",
        "def find_optimal_split(X, y):\n",
        "  optim_threshold = 0\n",
        "  optim_ig = 0\n",
        "  optim_left_entropy = 0\n",
        "  optim_right_entropy = 0\n",
        "  m, n = X.shape\n",
        "  # Compute thresholds for each feature\n",
        "  for i in range(n):\n",
        "    thresholds = calculate_thresholds(X[:, i])\n",
        "    # Traverse over thresholds\n",
        "    for thresh in thresholds:\n",
        "      # Splitting\n",
        "      left_node, right_node, left_node_classes, right_node_classes = split(X[:, i], y, thresh)\n",
        "\n",
        "      # Evaluate the split\n",
        "      root_entropy = calculate_entropy(y)\n",
        "      ln_entropy = calculate_entropy(left_node_classes)\n",
        "      rn_entropy = calculate_entropy(right_node_classes)\n",
        "      ig = root_entropy - (ln_entropy * len(left_node)/m + rn_entropy * len(right_node)/m)\n",
        "      # Assign optimal params\n",
        "      if ig > optim_ig:\n",
        "        optim_feature = i\n",
        "        optim_ig = ig\n",
        "        optim_threshold = thresh\n",
        "        optim_left_entropy = ln_entropy\n",
        "        optim_right_entropy = rn_entropy\n",
        "  return optim_feature, optim_threshold, optim_ig, optim_left_entropy, optim_right_entropy"
      ],
      "metadata": {
        "id": "jwhS0yI5iNme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "# shuffle the data\n",
        "X = data.data\n",
        "y = data.target\n",
        "# shuffle the dataset\n",
        "np.random.seed(42)\n",
        "dataset = np.c_[X, y]\n",
        "np.random.shuffle(dataset)\n",
        "shuffled_X = dataset[:, :-1]\n",
        "shuffled_y = dataset[:, -1]\n",
        "shuffled_y = shuffled_y.astype(int)"
      ],
      "metadata": {
        "id": "3WicBnJr1E3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_optimal_split(shuffled_X, shuffled_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQq8Kcauj3O9",
        "outputId": "190e19e3-710a-4238-bf99-f19545d8a376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2,\n",
              " np.float64(1.9),\n",
              " np.float64(0.9182958340544894),\n",
              " np.float64(0.0),\n",
              " np.float64(1.0))"
            ]
          },
          "metadata": {},
          "execution_count": 384
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing\n",
        "X_ = shuffled_X[:, 2]\n",
        "y_pred = np.where(X_ <= 1.9, 0, 1)\n",
        "np.where(y_pred == 0, shuffled_y, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJfxITxPk78w",
        "outputId": "b77c6e31-55d2-43bd-840a-9376a5f622e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
              "       0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
              "       1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 385
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "binary_split(X, y, 3, 0.79)"
      ],
      "metadata": {
        "id": "V54NS6oVm7cy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96093d93-b6df-49c0-d4bb-5ba67d3bf198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[5.1, 3.5, 1.4, 0.2],\n",
              "        [4.9, 3. , 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.3, 0.2],\n",
              "        [4.6, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.6, 1.4, 0.2],\n",
              "        [5.4, 3.9, 1.7, 0.4],\n",
              "        [4.6, 3.4, 1.4, 0.3],\n",
              "        [5. , 3.4, 1.5, 0.2],\n",
              "        [4.4, 2.9, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.1],\n",
              "        [5.4, 3.7, 1.5, 0.2],\n",
              "        [4.8, 3.4, 1.6, 0.2],\n",
              "        [4.8, 3. , 1.4, 0.1],\n",
              "        [4.3, 3. , 1.1, 0.1],\n",
              "        [5.8, 4. , 1.2, 0.2],\n",
              "        [5.7, 4.4, 1.5, 0.4],\n",
              "        [5.4, 3.9, 1.3, 0.4],\n",
              "        [5.1, 3.5, 1.4, 0.3],\n",
              "        [5.7, 3.8, 1.7, 0.3],\n",
              "        [5.1, 3.8, 1.5, 0.3],\n",
              "        [5.4, 3.4, 1.7, 0.2],\n",
              "        [5.1, 3.7, 1.5, 0.4],\n",
              "        [4.6, 3.6, 1. , 0.2],\n",
              "        [5.1, 3.3, 1.7, 0.5],\n",
              "        [4.8, 3.4, 1.9, 0.2],\n",
              "        [5. , 3. , 1.6, 0.2],\n",
              "        [5. , 3.4, 1.6, 0.4],\n",
              "        [5.2, 3.5, 1.5, 0.2],\n",
              "        [5.2, 3.4, 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.6, 0.2],\n",
              "        [4.8, 3.1, 1.6, 0.2],\n",
              "        [5.4, 3.4, 1.5, 0.4],\n",
              "        [5.2, 4.1, 1.5, 0.1],\n",
              "        [5.5, 4.2, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.2, 1.2, 0.2],\n",
              "        [5.5, 3.5, 1.3, 0.2],\n",
              "        [4.9, 3.6, 1.4, 0.1],\n",
              "        [4.4, 3. , 1.3, 0.2],\n",
              "        [5.1, 3.4, 1.5, 0.2],\n",
              "        [5. , 3.5, 1.3, 0.3],\n",
              "        [4.5, 2.3, 1.3, 0.3],\n",
              "        [4.4, 3.2, 1.3, 0.2],\n",
              "        [5. , 3.5, 1.6, 0.6],\n",
              "        [5.1, 3.8, 1.9, 0.4],\n",
              "        [4.8, 3. , 1.4, 0.3],\n",
              "        [5.1, 3.8, 1.6, 0.2],\n",
              "        [4.6, 3.2, 1.4, 0.2],\n",
              "        [5.3, 3.7, 1.5, 0.2],\n",
              "        [5. , 3.3, 1.4, 0.2]]),\n",
              " array([[7. , 3.2, 4.7, 1.4],\n",
              "        [6.4, 3.2, 4.5, 1.5],\n",
              "        [6.9, 3.1, 4.9, 1.5],\n",
              "        [5.5, 2.3, 4. , 1.3],\n",
              "        [6.5, 2.8, 4.6, 1.5],\n",
              "        [5.7, 2.8, 4.5, 1.3],\n",
              "        [6.3, 3.3, 4.7, 1.6],\n",
              "        [4.9, 2.4, 3.3, 1. ],\n",
              "        [6.6, 2.9, 4.6, 1.3],\n",
              "        [5.2, 2.7, 3.9, 1.4],\n",
              "        [5. , 2. , 3.5, 1. ],\n",
              "        [5.9, 3. , 4.2, 1.5],\n",
              "        [6. , 2.2, 4. , 1. ],\n",
              "        [6.1, 2.9, 4.7, 1.4],\n",
              "        [5.6, 2.9, 3.6, 1.3],\n",
              "        [6.7, 3.1, 4.4, 1.4],\n",
              "        [5.6, 3. , 4.5, 1.5],\n",
              "        [5.8, 2.7, 4.1, 1. ],\n",
              "        [6.2, 2.2, 4.5, 1.5],\n",
              "        [5.6, 2.5, 3.9, 1.1],\n",
              "        [5.9, 3.2, 4.8, 1.8],\n",
              "        [6.1, 2.8, 4. , 1.3],\n",
              "        [6.3, 2.5, 4.9, 1.5],\n",
              "        [6.1, 2.8, 4.7, 1.2],\n",
              "        [6.4, 2.9, 4.3, 1.3],\n",
              "        [6.6, 3. , 4.4, 1.4],\n",
              "        [6.8, 2.8, 4.8, 1.4],\n",
              "        [6.7, 3. , 5. , 1.7],\n",
              "        [6. , 2.9, 4.5, 1.5],\n",
              "        [5.7, 2.6, 3.5, 1. ],\n",
              "        [5.5, 2.4, 3.8, 1.1],\n",
              "        [5.5, 2.4, 3.7, 1. ],\n",
              "        [5.8, 2.7, 3.9, 1.2],\n",
              "        [6. , 2.7, 5.1, 1.6],\n",
              "        [5.4, 3. , 4.5, 1.5],\n",
              "        [6. , 3.4, 4.5, 1.6],\n",
              "        [6.7, 3.1, 4.7, 1.5],\n",
              "        [6.3, 2.3, 4.4, 1.3],\n",
              "        [5.6, 3. , 4.1, 1.3],\n",
              "        [5.5, 2.5, 4. , 1.3],\n",
              "        [5.5, 2.6, 4.4, 1.2],\n",
              "        [6.1, 3. , 4.6, 1.4],\n",
              "        [5.8, 2.6, 4. , 1.2],\n",
              "        [5. , 2.3, 3.3, 1. ],\n",
              "        [5.6, 2.7, 4.2, 1.3],\n",
              "        [5.7, 3. , 4.2, 1.2],\n",
              "        [5.7, 2.9, 4.2, 1.3],\n",
              "        [6.2, 2.9, 4.3, 1.3],\n",
              "        [5.1, 2.5, 3. , 1.1],\n",
              "        [5.7, 2.8, 4.1, 1.3],\n",
              "        [6.3, 3.3, 6. , 2.5],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [7.1, 3. , 5.9, 2.1],\n",
              "        [6.3, 2.9, 5.6, 1.8],\n",
              "        [6.5, 3. , 5.8, 2.2],\n",
              "        [7.6, 3. , 6.6, 2.1],\n",
              "        [4.9, 2.5, 4.5, 1.7],\n",
              "        [7.3, 2.9, 6.3, 1.8],\n",
              "        [6.7, 2.5, 5.8, 1.8],\n",
              "        [7.2, 3.6, 6.1, 2.5],\n",
              "        [6.5, 3.2, 5.1, 2. ],\n",
              "        [6.4, 2.7, 5.3, 1.9],\n",
              "        [6.8, 3. , 5.5, 2.1],\n",
              "        [5.7, 2.5, 5. , 2. ],\n",
              "        [5.8, 2.8, 5.1, 2.4],\n",
              "        [6.4, 3.2, 5.3, 2.3],\n",
              "        [6.5, 3. , 5.5, 1.8],\n",
              "        [7.7, 3.8, 6.7, 2.2],\n",
              "        [7.7, 2.6, 6.9, 2.3],\n",
              "        [6. , 2.2, 5. , 1.5],\n",
              "        [6.9, 3.2, 5.7, 2.3],\n",
              "        [5.6, 2.8, 4.9, 2. ],\n",
              "        [7.7, 2.8, 6.7, 2. ],\n",
              "        [6.3, 2.7, 4.9, 1.8],\n",
              "        [6.7, 3.3, 5.7, 2.1],\n",
              "        [7.2, 3.2, 6. , 1.8],\n",
              "        [6.2, 2.8, 4.8, 1.8],\n",
              "        [6.1, 3. , 4.9, 1.8],\n",
              "        [6.4, 2.8, 5.6, 2.1],\n",
              "        [7.2, 3. , 5.8, 1.6],\n",
              "        [7.4, 2.8, 6.1, 1.9],\n",
              "        [7.9, 3.8, 6.4, 2. ],\n",
              "        [6.4, 2.8, 5.6, 2.2],\n",
              "        [6.3, 2.8, 5.1, 1.5],\n",
              "        [6.1, 2.6, 5.6, 1.4],\n",
              "        [7.7, 3. , 6.1, 2.3],\n",
              "        [6.3, 3.4, 5.6, 2.4],\n",
              "        [6.4, 3.1, 5.5, 1.8],\n",
              "        [6. , 3. , 4.8, 1.8],\n",
              "        [6.9, 3.1, 5.4, 2.1],\n",
              "        [6.7, 3.1, 5.6, 2.4],\n",
              "        [6.9, 3.1, 5.1, 2.3],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [6.8, 3.2, 5.9, 2.3],\n",
              "        [6.7, 3.3, 5.7, 2.5],\n",
              "        [6.7, 3. , 5.2, 2.3],\n",
              "        [6.3, 2.5, 5. , 1.9],\n",
              "        [6.5, 3. , 5.2, 2. ],\n",
              "        [6.2, 3.4, 5.4, 2.3],\n",
              "        [5.9, 3. , 5.1, 1.8]]),\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 386
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assemble everything and return the optimal threshold\n",
        "def best_split(root_values, root_labels, thresholds):\n",
        "  optimal_threshold = 0\n",
        "  optimal_ig = 0\n",
        "  optim_left_etropy = 0\n",
        "  optim_right_etropy = 0\n",
        "  n = len(root_labels)\n",
        "  for thresh in thresholds:\n",
        "    # Traverse over thresholds and split\n",
        "    left_node, right_node, left_node_classes, right_node_classes = split(root_values, root_labels, thresh)\n",
        "\n",
        "    # Evaluate each split\n",
        "    root_entropy = calculate_entropy(root_labels)\n",
        "    ln_entropy = calculate_entropy(left_node_classes)\n",
        "    rn_entropy = calculate_entropy(right_node_classes)\n",
        "    ig = root_entropy - (ln_entropy * len(left_node)/n + rn_entropy * len(right_node)/n)\n",
        "    if ig > optimal_ig:\n",
        "      optimal_ig = ig\n",
        "      optimal_threshold = thresh\n",
        "      optim_left_etropy = ln_entropy\n",
        "      optim_right_etropy = rn_entropy\n",
        "  return optimal_threshold, optimal_ig"
      ],
      "metadata": {
        "id": "Roq7gMSs_g7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_split(age, labels, thresholds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LY1SzzgmXME",
        "outputId": "4bc27ec4-deea-48a8-dce2-5674620e62d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(21.5), np.float64(0.9182958340544894))"
            ]
          },
          "metadata": {},
          "execution_count": 388
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(y, return_counts=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSr1rkjsyBvu",
        "outputId": "dd6557d9-4ad2-44b1-9a6c-bfd16bbd23fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2]), array([50, 50, 50]))"
            ]
          },
          "metadata": {},
          "execution_count": 389
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------Reformatted"
      ],
      "metadata": {
        "id": "40bJeSw50EzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_thresholds(X, n_components=2):\n",
        "  # sort the values in ascending order\n",
        "  sorted_X = sorted(X, reverse=False)\n",
        "  sorted_X = np.array(sorted_X)\n",
        "  result = []\n",
        "  for i in range(len(sorted_X)-n_components+1):\n",
        "    selected_comps = sorted_X[i:i+n_components]\n",
        "    result.append(sum(selected_comps)/n_components)\n",
        "  return np.array(result)"
      ],
      "metadata": {
        "id": "IrSe_ohS0DjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_entropy(node_labels):\n",
        "  # get the unique labels\n",
        "  unique_labels = np.unique(node_labels)\n",
        "  total_class = len(node_labels) # total number of classes\n",
        "  # calculate the entropy for each class and sum it up\n",
        "  entropy = 0\n",
        "  for i in unique_labels:\n",
        "    n_classi = sum(node_labels == i) # number of elements of classi\n",
        "    pi =  n_classi / total_class\n",
        "    entropy += (-pi * np.log2(pi))\n",
        "  return entropy # 0: homogenious, 1: class labels are equally divided"
      ],
      "metadata": {
        "id": "dp1A1Llu3l3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_split(X, y, feature, threshold):\n",
        "  left_node = []\n",
        "  right_node = []\n",
        "  left_node_classes = []\n",
        "  right_node_classes = []\n",
        "  m, n = X.shape\n",
        "  preds = np.where(X[:, feature] <= threshold, 0, 1)\n",
        "  for i in range(m):\n",
        "    if preds[i] == 0:\n",
        "      left_node.append(X[i])\n",
        "      if y is not None:\n",
        "        left_node_classes.append(y[i])\n",
        "    else:\n",
        "      right_node.append(X[i])\n",
        "      if y is not None:\n",
        "        right_node_classes.append(y[i])\n",
        "  return np.array(left_node), np.array(right_node), np.array(left_node_classes), np.array(right_node_classes)"
      ],
      "metadata": {
        "id": "G_8DbUCk0NDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assemble everything and return the optimal threshold\n",
        "def find_optimal_split(X, y, feature_constraint=False):\n",
        "  optim_feature = 0\n",
        "  optim_threshold = 0\n",
        "  optim_ig = 0\n",
        "  optim_left_entropy = 0\n",
        "  optim_right_entropy = 0\n",
        "  m, n = X.shape\n",
        "\n",
        "  # check for feature constraint\n",
        "  if feature_constraint:\n",
        "    n_sampled_features = int(np.sqrt(n))\n",
        "  else:\n",
        "    n_sampled_features = n\n",
        "  # randomly sample feature choices for the split\n",
        "  sampled_features = np.random.choice(n, n_sampled_features, replace=False)\n",
        "\n",
        "  # Compute thresholds for feature choices\n",
        "  for i in range(len(sampled_features)):\n",
        "    thresholds = calculate_thresholds(X[:, sampled_features[i]])\n",
        "\n",
        "    # Traverse over thresholds\n",
        "    for thresh in thresholds:\n",
        "      # Splitting\n",
        "      left_node, right_node, left_node_classes, right_node_classes = binary_split(X, y, sampled_features[i], thresh)\n",
        "\n",
        "      # Evaluate the split\n",
        "      root_entropy = calculate_entropy(y)\n",
        "      ln_entropy = calculate_entropy(left_node_classes)\n",
        "      rn_entropy = calculate_entropy(right_node_classes)\n",
        "      ig = root_entropy - (ln_entropy * len(left_node)/m + rn_entropy * len(right_node)/m)\n",
        "      #optim_feature, optim_threshold, optim_ig, optim_left_entropy, optim_right_entropy = i, thresh, ig, ln_entropy, rn_entropy\n",
        "\n",
        "      # Assign optimal params\n",
        "      if ig >= optim_ig:\n",
        "        optim_feature = sampled_features[i]\n",
        "        optim_ig = ig\n",
        "        optim_threshold = thresh\n",
        "        optim_left_entropy = ln_entropy\n",
        "        optim_right_entropy = rn_entropy\n",
        "  return optim_feature, optim_threshold, optim_ig, optim_left_entropy, optim_right_entropy"
      ],
      "metadata": {
        "id": "hbiY-8Nz0qyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_leaf_node(y, n_classes):\n",
        "  ytoc = np.zeros(n_classes, dtype=\"int\") # y to counts\n",
        "  unique_labels, counts = np.unique(y, return_counts=True)\n",
        "  ytoc[unique_labels] = counts\n",
        "  target_class = unique_labels[np.argmax(counts)]\n",
        "  entropy_ = calculate_entropy(y)\n",
        "  n_samples_ = len(y)\n",
        "  return (entropy_, n_samples_, ytoc, target_class)"
      ],
      "metadata": {
        "id": "kYqur-gHf4SH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "  def __init__(self, entropy, n_samples, values, label=None, feature=None, threshold=None, left_node=None, right_node=None):\n",
        "    self.feature = feature\n",
        "    self.threshold = threshold\n",
        "    self.entropy = entropy\n",
        "    self.n_samples = n_samples\n",
        "    self.values = values\n",
        "    self.label = label\n",
        "    self.left_node = left_node\n",
        "    self.right_node = right_node\n",
        "\n",
        "  def print_tree(self):\n",
        "    print(self)\n",
        "    if self.left_node:\n",
        "      self.left_node.print_tree()\n",
        "    if self.right_node:\n",
        "      self.right_node.print_tree()\n",
        "\n",
        "  def __repr__(self):\n",
        "    return f\"Node(feature={self.feature}, threshold={self.threshold}, entropy={self.entropy}, n_samples={self.n_samples}, values={self.values}, class={self.label})\""
      ],
      "metadata": {
        "id": "2FS45N5S_0rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_tree(X, y, max_depth, max_leaf, depth=0, leaf=0, n_classes=3, feature_constraint=False):\n",
        "\n",
        "  # Stopping criteria\n",
        "  if depth >= max_depth or leaf >= max_leaf:\n",
        "    entropy, n_samples, target_values, target_class = compute_leaf_node(y, n_classes)\n",
        "    return Node(entropy, n_samples, target_values, label=target_class)\n",
        "\n",
        "  # get n_samples and n_features\n",
        "  m, n = X.shape\n",
        "  # get target values counts\n",
        "  target_values = np.zeros(n_classes, dtype=\"int\")\n",
        "  unique_labels, counts = np.unique(y, return_counts=True)\n",
        "  target_values[unique_labels] = counts\n",
        "  # Compute the root entropy\n",
        "  root_entropy = calculate_entropy(y)\n",
        "  if root_entropy == 0: # The class is homogeneous\n",
        "    entropy, n_samples, target_values, target_class = compute_leaf_node(y, n_classes)\n",
        "    return Node(entropy, n_samples, target_values, label=target_class)\n",
        "  else:\n",
        "    # Find the optimal feature and threshold\n",
        "    optimal_feature, optimal_threshold, optimal_ig, left_node_entropy, right_node_entropy = find_optimal_split(X, y, feature_constraint)\n",
        "    left_node, right_node, left_node_classes, right_node_classes = binary_split(X, y, optimal_feature, optimal_threshold)\n",
        "\n",
        "    # Check for leaf node\n",
        "    if left_node_entropy == 0:\n",
        "      leaf += 1\n",
        "\n",
        "    if right_node_entropy == 0:\n",
        "      leaf += 1\n",
        "\n",
        "    # Recursively branching\n",
        "    left_node = build_tree(left_node, left_node_classes, max_depth, max_leaf, depth+1, leaf, feature_constraint=feature_constraint)\n",
        "    right_node = build_tree(right_node, right_node_classes, max_depth, max_leaf, depth+1, leaf, feature_constraint=feature_constraint)\n",
        "  return Node(entropy=root_entropy, n_samples=m, values=target_values, feature=optimal_feature, threshold=optimal_threshold, left_node=left_node, right_node=right_node)"
      ],
      "metadata": {
        "id": "qsDfZtVMeGMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "# shuffle the data\n",
        "X = data.data\n",
        "y = data.target\n",
        "# shuffle the dataset\n",
        "np.random.seed(42)\n",
        "dataset = np.c_[X, y]\n",
        "np.random.shuffle(dataset)\n",
        "shuffled_X = dataset[:, :-1]\n",
        "shuffled_y = dataset[:, -1]\n",
        "shuffled_y = shuffled_y.astype(int)"
      ],
      "metadata": {
        "id": "gsrKTzi2jqJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(shuffled_X, shuffled_y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "-VOMSW-HqFGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree = build_tree(shuffled_X, shuffled_y, 4, 4)"
      ],
      "metadata": {
        "id": "2_SgJm9ImI5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree.print_tree()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrnP5eg7n1-R",
        "outputId": "98023263-5b9f-41b7-bdb5-f5bc997f48cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node(feature=2, threshold=2.45, entropy=1.584962500721156, n_samples=150, values=[50 50 50], class=None)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=50, values=[50  0  0], class=0)\n",
            "Node(feature=3, threshold=1.75, entropy=1.0, n_samples=100, values=[ 0 50 50], class=None)\n",
            "Node(feature=2, threshold=4.95, entropy=0.44506485705083865, n_samples=54, values=[ 0 49  5], class=None)\n",
            "Node(feature=3, threshold=1.65, entropy=0.1460942501201363, n_samples=48, values=[ 0 47  1], class=None)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=47, values=[ 0 47  0], class=1)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=1, values=[0 0 1], class=2)\n",
            "Node(feature=3, threshold=1.55, entropy=0.9182958340544896, n_samples=6, values=[0 2 4], class=None)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=3, values=[0 0 3], class=2)\n",
            "Node(feature=None, threshold=None, entropy=0.9182958340544896, n_samples=3, values=[0 2 1], class=1)\n",
            "Node(feature=2, threshold=4.85, entropy=0.15109697051711368, n_samples=46, values=[ 0  1 45], class=None)\n",
            "Node(feature=0, threshold=5.95, entropy=0.9182958340544896, n_samples=3, values=[0 1 2], class=None)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=1, values=[0 1 0], class=1)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=2, values=[0 0 2], class=2)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=43, values=[ 0  0 43], class=2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OOP Assemble"
      ],
      "metadata": {
        "id": "l6gnO-BVi7ZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def traverse(X, node):\n",
        "    # check for leaf node\n",
        "    if node.feature == None:\n",
        "      # calculate current n_samples and correspond class\n",
        "      return node.label\n",
        "\n",
        "    # get attributes from nodes\n",
        "    feature = node.feature\n",
        "    threshold = node.threshold\n",
        "\n",
        "    if X[feature] <= threshold:\n",
        "      # go to the left node\n",
        "      return traverse(X, node.left_node)\n",
        "    else:\n",
        "      # go to the right node\n",
        "      return traverse(X, node.right_node)"
      ],
      "metadata": {
        "id": "QIwim6AdmFU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTreesClassifier:\n",
        "  def __init__(self, max_depth, max_leaf, min_samples_leaf=None, min_samples_split=None):\n",
        "    self.max_depth = max_depth\n",
        "    self.max_leaf = max_leaf\n",
        "    self.min_samples_leaf = min_samples_leaf\n",
        "    self.min_samples_split = min_samples_split\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    n_classes = np.unique(y).size\n",
        "    self.tree = build_tree(X, y, max_depth=self.max_depth, max_leaf=self.max_leaf, n_classes=n_classes)\n",
        "\n",
        "  def predict(self, X, **kwargs):\n",
        "    m = X.shape[0]\n",
        "    # create a place holder for predictions\n",
        "    y_pred = []\n",
        "    # go through each example\n",
        "    for i in range(m):\n",
        "      pred = traverse(X[i], self.tree)\n",
        "      y_pred.append(pred)\n",
        "    return np.array(y_pred)\n",
        "\n",
        "  def score(self, X, y, **kwargs):\n",
        "    y_pred = self.predict(X)\n",
        "    return (y_pred == y).sum() / len(y)"
      ],
      "metadata": {
        "id": "dgFVhkn-sEtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = DecisionTreesClassifier(4, 3)"
      ],
      "metadata": {
        "id": "p-daHuoviv6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "u658M6JzjaIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.tree.print_tree()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Slo1H53Ejhvg",
        "outputId": "b67774f5-b6b1-4ce1-d7b8-85374ab9964a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node(feature=3, threshold=0.8, entropy=1.5840680553754911, n_samples=120, values=[39 39 42], class=None)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=39, values=[39  0  0], class=0)\n",
            "Node(feature=3, threshold=1.75, entropy=0.9990102708804813, n_samples=81, values=[ 0 39 42], class=None)\n",
            "Node(feature=2, threshold=4.95, entropy=0.4537163391869448, n_samples=42, values=[ 0 38  4], class=None)\n",
            "Node(feature=3, threshold=1.65, entropy=0.1792560669283215, n_samples=37, values=[ 0 36  1], class=None)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=36, values=[ 0 36  0], class=1)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=1, values=[0 0 1], class=2)\n",
            "Node(feature=3, threshold=1.55, entropy=0.9709505944546686, n_samples=5, values=[0 2 3], class=None)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=3, values=[0 0 3], class=2)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=2, values=[0 2 0], class=1)\n",
            "Node(feature=2, threshold=4.85, entropy=0.17203694935311378, n_samples=39, values=[ 0  1 38], class=None)\n",
            "Node(feature=1, threshold=3.1, entropy=0.9182958340544896, n_samples=3, values=[0 1 2], class=None)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=2, values=[0 0 2], class=2)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=1, values=[0 1 0], class=1)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=36, values=[ 0  0 36], class=2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnPVef5NjxkA",
        "outputId": "388f6593-62ed-46f0-9698-0eb5219fe823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 1, 0, 2, 0, 1, 1, 0, 0, 1, 0, 1, 1, 2, 0, 2, 1, 1, 0, 0, 2,\n",
              "       2, 0, 1, 1, 0, 2, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 407
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "classifier.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "surVPYBIkAT8",
        "outputId": "71c042a4-d7bd-44c3-fc8d-5a90df4ea725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.9666666666666667)"
            ]
          },
          "metadata": {},
          "execution_count": 408
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Improvements\n",
        "\n",
        "<li>I definitely could optimize the code more...\n",
        "<li>The predict method could be more parralelism i.e compute all the test data points in one go"
      ],
      "metadata": {
        "id": "ZMCwJAOH6WZ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forests"
      ],
      "metadata": {
        "id": "aR5ZJ3CpJAfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sampling with replacement\n",
        "def replacement_sampling(X, S, replace=True):\n",
        "  \"\"\"\n",
        "  Perform sampling with replacement(Bagging)\n",
        "  Args:\n",
        "    X: the dataset to sample from\n",
        "    S: number of samples to sample from dataset\n",
        "\n",
        "  Return:\n",
        "    A list of sample from dataset(n_samples, X.shape[1])\n",
        "  \"\"\"\n",
        "  idx = np.random.choice(len(X), S, replace=replace)\n",
        "  return X[idx]"
      ],
      "metadata": {
        "id": "XSW2vFhiJCRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample B batches from dataset with length = n_samples\n",
        "def batches_sampling(X, S, B):\n",
        "  \"\"\"\n",
        "  Sample B batches from the provided dataset\n",
        "  Args:\n",
        "    dataset: dataset to sample from\n",
        "    n_samples: number of samples/batch\n",
        "    B: number of batches\n",
        "\n",
        "  Return:\n",
        "    A list of sampled batches(B, S, X.shape[1])\n",
        "  \"\"\"\n",
        "  result = []\n",
        "  for b in range(B-1):\n",
        "    sampled_batch = replacement_sampling(X, S)\n",
        "    result.append(sampled_batch)\n",
        "  return np.array(result)"
      ],
      "metadata": {
        "id": "l2jnifjGJDXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batches = batches_sampling(dataset, len(dataset), 5)"
      ],
      "metadata": {
        "id": "3ppMp2r6JE2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batches.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4MN0bUKJINj",
        "outputId": "17189e07-a43f-474b-eedf-165ef5ff2201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 150, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 412
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train a decision tree for each sampled batch\n",
        "for b in batches:\n",
        "  X = b[:, :-1]\n",
        "  y = b[:, -1]\n",
        "  y = y.astype(int) # convert to int\n",
        "  tree = build_tree(X, y, 4, 4)\n",
        "  tree.print_tree()\n",
        "  print('--------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXJmGHiRJVx4",
        "outputId": "cd5ae26f-dcab-4fc2-bba3-f93a62ab2382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node(feature=2, threshold=2.5999999999999996, entropy=1.5728297468290475, n_samples=150, values=[41 55 54], class=None)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=41, values=[41  0  0], class=0)\n",
            "Node(feature=3, threshold=1.65, entropy=0.999939284770655, n_samples=109, values=[ 0 55 54], class=None)\n",
            "Node(feature=1, threshold=2.3, entropy=0.42368057157091055, n_samples=58, values=[ 0 53  5], class=None)\n",
            "Node(feature=2, threshold=4.75, entropy=0.954434002924965, n_samples=8, values=[0 3 5], class=None)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=3, values=[0 3 0], class=1)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=5, values=[0 0 5], class=2)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=50, values=[ 0 50  0], class=1)\n",
            "Node(feature=2, threshold=4.85, entropy=0.23868451135100135, n_samples=51, values=[ 0  2 49], class=None)\n",
            "Node(feature=1, threshold=3.0, entropy=0.7642045065086203, n_samples=9, values=[0 2 7], class=None)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=7, values=[0 0 7], class=2)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=2, values=[0 2 0], class=1)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=42, values=[ 0  0 42], class=2)\n",
            "--------------------\n",
            "Node(feature=3, threshold=0.8, entropy=1.580955913268387, n_samples=150, values=[55 46 49], class=None)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=55, values=[55  0  0], class=0)\n",
            "Node(feature=2, threshold=4.85, entropy=0.9992805310649711, n_samples=95, values=[ 0 46 49], class=None)\n",
            "Node(feature=0, threshold=4.95, entropy=0.2623112196143366, n_samples=45, values=[ 0 43  2], class=None)\n",
            "Node(feature=1, threshold=2.45, entropy=0.9182958340544896, n_samples=3, values=[0 1 2], class=None)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=1, values=[0 1 0], class=1)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=2, values=[0 0 2], class=2)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=42, values=[ 0 42  0], class=1)\n",
            "Node(feature=3, threshold=1.75, entropy=0.32744491915447627, n_samples=50, values=[ 0  3 47], class=None)\n",
            "Node(feature=3, threshold=1.55, entropy=0.8812908992306927, n_samples=10, values=[0 3 7], class=None)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=7, values=[0 0 7], class=2)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=3, values=[0 3 0], class=1)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=40, values=[ 0  0 40], class=2)\n",
            "--------------------\n",
            "Node(feature=2, threshold=2.45, entropy=1.576585673642799, n_samples=150, values=[43 56 51], class=None)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=43, values=[43  0  0], class=0)\n",
            "Node(feature=2, threshold=4.85, entropy=0.9984242941042114, n_samples=107, values=[ 0 56 51], class=None)\n",
            "Node(feature=3, threshold=1.65, entropy=0.3013786435930858, n_samples=56, values=[ 0 53  3], class=None)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=51, values=[ 0 51  0], class=1)\n",
            "Node(feature=1, threshold=3.0, entropy=0.9709505944546686, n_samples=5, values=[0 2 3], class=None)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=3, values=[0 0 3], class=2)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=2, values=[0 2 0], class=1)\n",
            "Node(feature=3, threshold=1.75, entropy=0.3227569588973982, n_samples=51, values=[ 0  3 48], class=None)\n",
            "Node(feature=1, threshold=2.9, entropy=0.8812908992306927, n_samples=10, values=[0 3 7], class=None)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=6, values=[0 0 6], class=2)\n",
            "Node(feature=None, threshold=None, entropy=0.8112781244591328, n_samples=4, values=[0 3 1], class=1)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=41, values=[ 0  0 41], class=2)\n",
            "--------------------\n",
            "Node(feature=2, threshold=2.35, entropy=1.5826214860605732, n_samples=150, values=[52 46 52], class=None)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=52, values=[52  0  0], class=0)\n",
            "Node(feature=2, threshold=4.75, entropy=0.9972943816462347, n_samples=98, values=[ 0 46 52], class=None)\n",
            "Node(feature=3, threshold=1.6, entropy=0.1654270339962668, n_samples=41, values=[ 0 40  1], class=None)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=40, values=[ 0 40  0], class=1)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=1, values=[0 0 1], class=2)\n",
            "Node(feature=2, threshold=5.15, entropy=0.4854607607459134, n_samples=57, values=[ 0  6 51], class=None)\n",
            "Node(feature=3, threshold=1.75, entropy=0.863120568566631, n_samples=21, values=[ 0  6 15], class=None)\n",
            "Node(feature=None, threshold=None, entropy=0.9910760598382222, n_samples=9, values=[0 5 4], class=1)\n",
            "Node(feature=None, threshold=None, entropy=0.41381685030363374, n_samples=12, values=[ 0  1 11], class=2)\n",
            "Node(feature=None, threshold=None, entropy=0.0, n_samples=36, values=[ 0  0 36], class=2)\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicRandomForest():\n",
        "  def __init__(self, n_trees, B, max_depth, max_leaf, min_samples_leaf=None, min_samples_split=None): # only support max_depth and max_leaf for now\n",
        "    self.n_trees = n_trees\n",
        "    self.B = B\n",
        "    self.max_depth = max_depth\n",
        "    self.max_leaf = max_leaf\n",
        "    self.min_samples_leaf = min_samples_leaf\n",
        "    self.min_samples_split = min_samples_split\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    # concat X and y\n",
        "    dataset = np.c_[X, y]\n",
        "    # sample B batches from dataset with length = n_samples\n",
        "    batches = batches_sampling(dataset, self.B, self.n_trees)\n",
        "    self.trees = []\n",
        "    for b in batches:\n",
        "      X = b[:, :-1]\n",
        "      y = b[:, -1].astype(int)\n",
        "      tree = build_tree(X, y, max_depth=self.max_depth, max_leaf=self.max_leaf, feature_constraint=True)\n",
        "      self.trees.append(tree)\n",
        "\n",
        "  def predict(self, X, **kwargs):\n",
        "    m = X.shape[0]\n",
        "    # create a place holder for predictions\n",
        "    y_pred = []\n",
        "    # go through each example\n",
        "    for i in range(m):\n",
        "      preds = []\n",
        "      # predict on each tree\n",
        "      for tree in self.trees:\n",
        "        pred = traverse(X[i], tree)\n",
        "        preds.append(pred)\n",
        "      labels, counts = np.unique(np.array(preds), return_counts=True)\n",
        "      y_pred.append(labels[np.argmax(counts)])\n",
        "    return np.array(y_pred)\n",
        "\n",
        "  def score(self, X, y, **kwargs):\n",
        "    y_pred = self.predict(X)\n",
        "    accuracy = (y_pred == y).sum() / len(y)\n",
        "    return accuracy.item()\n"
      ],
      "metadata": {
        "id": "rujf6BBnJqbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfc = BasicRandomForest(10, 10, 4, 4)"
      ],
      "metadata": {
        "id": "00ui_Az0SRJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfc.fit(X_train, y_train)\n",
        "y_pred = rfc.predict(X_test)\n",
        "y_test == y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRvbU9-JWDPT",
        "outputId": "e045d159-6da4-497e-908a-102686e6f70a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
              "        True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 424
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfc.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "BmL00Y_wWGV-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6277759f-6d6a-4484-f6b9-8a0d0d9cb6d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 425
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ey1t--L0bJ24"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}